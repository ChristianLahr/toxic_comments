{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christof/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/christof/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n",
      "lowercase\n",
      "removing breaks\n",
      "expanding contractions\n",
      "replacing smileys\n",
      "replacing ip\n",
      "removing links\n",
      "replacing numbers\n",
      "removing bigrams\n",
      "isolating punct\n",
      "preprocessing\n",
      "lowercase\n",
      "removing breaks\n",
      "expanding contractions\n",
      "replacing smileys\n",
      "replacing ip\n",
      "removing links\n",
      "replacing numbers\n",
      "removing bigrams\n",
      "isolating punct\n",
      "fitting tokenizer\n"
     ]
    }
   ],
   "source": [
    "import re, os, gc, time, pandas as pd, numpy as np\n",
    "import tqdm\n",
    "\n",
    "np.random.seed(32)\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"5\"\n",
    "from nltk import tokenize, word_tokenize\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, Add, Flatten, TimeDistributed,CuDNNGRU,CuDNNLSTM\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras import backend as K\n",
    "# from keras.engine.topology import Layer\n",
    "from keras.engine import InputSpec, Layer\n",
    "from preprocess_utils import preprocess\n",
    "from global_variables import TRAIN_FILENAME, TEST_FILENAME, COMMENT, LIST_CLASSES, UNKNOWN_WORD\n",
    "import logging\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "   \n",
    "embed_size = 300\n",
    "max_features = 150000\n",
    "max_text_len = 300\n",
    "\n",
    "# EMBEDDING_FILE = \"../input/glove840b300dtxt/glove.840B.300d.txt\n",
    "EMBEDDING_FILE = \"assets/embedding_models/ft_300d_crawl/crawl-300d-2M.vec\"\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch + 1, score))\n",
    "\n",
    "def rm_hyperlinks(words):\n",
    "    words = [w if not (w.startswith('http') or\n",
    "                       w.startswith('www') or\n",
    "                       w.endswith('.com') or\n",
    "                        w.startswith('en.wikipedia.org/')) else 'url' for w in words]\n",
    "    return words\n",
    "\n",
    "def strip_spaces(words):\n",
    "    return [w.replace(' ', '') for w in words]\n",
    "\n",
    "def tokenize_sentences(sentences):\n",
    "    twitter_tokenizer = TweetTokenizer()\n",
    "    tokenized_sentences = []\n",
    "    for sentence in tqdm.tqdm(sentences,mininterval=5):\n",
    "        if hasattr(sentence, \"decode\"):\n",
    "            sentence = sentence.decode(\"utf-8\")\n",
    "        tokens = twitter_tokenizer.tokenize(sentence)\n",
    "        tokenized_sentences.append(tokens)\n",
    "    return tokenized_sentences\n",
    "\n",
    "def tokenize_list_of_sentences(list_of_sentences):\n",
    "\n",
    "    list_of_tokenized_sentences = []\n",
    "    for sentences in list_of_sentences:\n",
    "        tokenized_sentences = tokenize_sentences(sentences)\n",
    "\n",
    "        # more preprocess on word level\n",
    "        tokenized_sentences = [rm_hyperlinks(s) for s in tokenized_sentences]\n",
    "        tokenized_sentences = [strip_spaces(s) for s in tokenized_sentences]\n",
    "        list_of_tokenized_sentences.append(tokenized_sentences)\n",
    "\n",
    "    return list_of_tokenized_sentences\n",
    "\n",
    "def create_word2id(list_of_tokenized_sentences,max_features):\n",
    "    word_counter = Counter()\n",
    "    print('CREATING VOCABULARY')\n",
    "    for tokenized_sentences in list_of_tokenized_sentences:\n",
    "        for tokens in tqdm.tqdm(tokenized_sentences):\n",
    "            word_counter.update(tokens)\n",
    "\n",
    "    raw_counts = word_counter.most_common(max_features)\n",
    "    vocab = [char_tuple[0] for char_tuple in raw_counts]\n",
    "    print('%s words detected, keeping %s words' % (len(word_counter), len(vocab)))\n",
    "    word2id = {word: (ind + 1) for ind, word in enumerate(vocab)}\n",
    "    word2id[UNKNOWN_WORD] = len(word2id)\n",
    "    id2word = dict((id, word) for word, id in word2id.items())\n",
    "    return word2id, id2word\n",
    "\n",
    "def tokenized_sentences2seq(tokenized_sentences, words_dict):\n",
    "    print('converting to sequence')\n",
    "    sequences = []\n",
    "    for sentence in tqdm.tqdm(tokenized_sentences, mininterval=5):\n",
    "        seq = []\n",
    "        for token in sentence:\n",
    "            try:\n",
    "                seq.append(words_dict[token])\n",
    "            except KeyError:\n",
    "                seq.append(words_dict[UNKNOWN_WORD])\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "def tokenized_sentences2seq2(tokenized_sentences, words_dict):\n",
    "    print('converting to sequence')\n",
    "    sequences = [words_dict[token] if token in words_dict else words_dict[UNKNOWN_WORD] for token in tqdm.tqdm(tokenized_sentences, mininterval=5)]\n",
    "    return sequences\n",
    "\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def convert_tokens_to_ids(tokenized_sentences, embedding_word_dict, id2word):\n",
    "    words_train = []\n",
    "    'converting word index to embedding index'\n",
    "    for sentence in tqdm.tqdm(tokenized_sentences):\n",
    "        current_words = []\n",
    "        for word_index in sentence:\n",
    "            try:\n",
    "                word = id2word[word_index]\n",
    "                word_id = embedding_word_dict.get(word, len(embedding_word_dict) - 2)\n",
    "            except KeyError:\n",
    "                word_id = embedding_word_dict.get(UNKNOWN_WORD, len(embedding_word_dict) - 2)\n",
    "            current_words.append(word_id)\n",
    "\n",
    "        if len(current_words) >= max_text_len:\n",
    "            current_words = current_words[:max_text_len]\n",
    "        else:\n",
    "            current_words += [len(embedding_word_dict) - 1] * (max_text_len - len(current_words))\n",
    "        words_train.append(current_words)\n",
    "    return words_train\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_FILENAME)\n",
    "test_data = pd.read_csv(TEST_FILENAME)\n",
    "Y = train_data[LIST_CLASSES].values\n",
    "\n",
    "test_data = preprocess(test_data)\n",
    "train_data = preprocess(train_data)\n",
    "\n",
    "train_data = train_data[\"comment_text\"].fillna(\"fillna\").values\n",
    "test_data = test_data[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "print('fitting tokenizer')\n",
    "tokenizer.fit_on_texts(list(train_data) + list(test_data))\n",
    "train_data = tokenizer.texts_to_sequences(train_data)\n",
    "test_data = tokenizer.texts_to_sequences(test_data)\n",
    "X = sequence.pad_sequences(train_data, maxlen=max_text_len)\n",
    "X_test = sequence.pad_sequences(test_data, maxlen=max_text_len)\n",
    "\n",
    "del train_data\n",
    "del test_data\n",
    "\n",
    "print('getting embeddings')\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import K, Activation\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Bidirectional, GRU, Flatten, SpatialDropout1D\n",
    "\n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    # s_squared_norm is really small\n",
    "    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n",
    "    # return scale * x\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# A Capsule Implement with Pure Keras\n",
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_31 (Embedding)     (None, 300, 300)          45000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_31 (Spatia (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "capsule_49 (Capsule)         (None, 64, 8)             153600    \n",
      "_________________________________________________________________\n",
      "capsule_50 (Capsule)         (None, 32, 8)             2048      \n",
      "_________________________________________________________________\n",
      "capsule_51 (Capsule)         (None, 16, 8)             1024      \n",
      "_________________________________________________________________\n",
      "capsule_52 (Capsule)         (None, 8, 8)              512       \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 45,157,574\n",
      "Trainable params: 157,574\n",
      "Non-trainable params: 45,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Routings = 5\n",
    "Num_capsule = 6\n",
    "Dim_capsule = 32\n",
    "dropout_p = 0.4\n",
    "rate_drop_dense = 0.4\n",
    "\n",
    "def build_model(lr=0.0):\n",
    "    inp = Input(shape=(max_text_len, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable=False)(inp)\n",
    "    x = SpatialDropout1D(rate_drop_dense)(x)\n",
    "    capsule = Capsule(num_capsule=64, dim_capsule=8, routings=Routings,share_weights=True)(x)\n",
    "    capsule = Capsule(num_capsule=32, dim_capsule=8, routings=Routings,share_weights=True)(capsule)\n",
    "    capsule = Capsule(num_capsule=16, dim_capsule=8, routings=Routings,share_weights=True)(capsule)\n",
    "    capsule = Capsule(num_capsule=8, dim_capsule=8, routings=Routings,share_weights=True)(capsule)\n",
    "    # output_capsule = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)))(capsule)\n",
    "    capsule = Flatten()(capsule)\n",
    "    capsule = Dropout(dropout_p)(capsule)\n",
    "    output = Dense(6, activation='sigmoid')(capsule)\n",
    "    model = Model(inputs=inp, outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(lr=1e-3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_37 (Embedding)     (None, 300, 300)          45000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_37 (Spatia (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 300, 512)          154112    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 300, 256)          131328    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 300, 256)          65792     \n",
      "_________________________________________________________________\n",
      "bidirectional_26 (Bidirectio (None, 128)               123648    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 45,475,654\n",
      "Trainable params: 475,654\n",
      "Non-trainable params: 45,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model(lr=0.0):\n",
    "    inp = Input(shape=(max_text_len, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable=False)(inp)\n",
    "    x = SpatialDropout1D(rate_drop_dense)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    # output_capsule = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)))(capsule)\n",
    "    x = Bidirectional(CuDNNGRU(64))(x)\n",
    "    output = Dense(6, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inp, outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(lr=1e-3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[150000,300]\n\t [[Node: embedding_39/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_39/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_39/embeddings, embedding_39/random_uniform)]]\n\nCaused by op 'embedding_39/embeddings/Assign', defined at:\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-a9d40830e021>\", line 15, in <module>\n    model = build_model(lr = 0.001)\n  File \"<ipython-input-21-f3c1eb1cbdc2>\", line 4, in build_model\n    x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable=False)(inp)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 105, in build\n    dtype=self.dtype)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[150000,300]\n\t [[Node: embedding_39/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_39/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_39/embeddings, embedding_39/random_uniform)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[150000,300]\n\t [[Node: embedding_39/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_39/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_39/embeddings, embedding_39/random_uniform)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a9d40830e021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfold_start\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"CAPS5_%s_.hdf5\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mfold_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mra_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRocAucEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-f3c1eb1cbdc2>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(lr)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_drop_dense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0;31m# Load weights that were specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \"\"\"\n\u001b[1;32m   2319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[150000,300]\n\t [[Node: embedding_39/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_39/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_39/embeddings, embedding_39/random_uniform)]]\n\nCaused by op 'embedding_39/embeddings/Assign', defined at:\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-a9d40830e021>\", line 15, in <module>\n    model = build_model(lr = 0.001)\n  File \"<ipython-input-21-f3c1eb1cbdc2>\", line 4, in build_model\n    x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable=False)(inp)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 105, in build\n    dtype=self.dtype)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[150000,300]\n\t [[Node: embedding_39/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_39/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_39/embeddings, embedding_39/random_uniform)]]\n"
     ]
    }
   ],
   "source": [
    "fold_count = 1\n",
    "fold_size = len(X) // 10\n",
    "for fold_id in range(fold_count):\n",
    "    fold_start = fold_size * fold_id\n",
    "    fold_end = fold_start + fold_size\n",
    "\n",
    "    if fold_id == 9:\n",
    "        fold_end = len(X)\n",
    "\n",
    "    X_valid = X[fold_start:fold_end]\n",
    "    Y_valid = Y[fold_start:fold_end]\n",
    "    X_train = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "    Y_train = np.concatenate([Y[:fold_start], Y[fold_end:]])\n",
    "\n",
    "    model = build_model(lr = 0.001)\n",
    "    file_path = \"CAPS5_%s_.hdf5\" %fold_id\n",
    "    ra_val = RocAucEvaluation(validation_data = (X_valid, Y_valid), interval = 1)\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "    history = model.fit(X_train, Y_train, batch_size = 128, epochs = 10, validation_data = (X_valid, Y_valid),\n",
    "                  verbose = 1, callbacks = [ra_val, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_count = 10\n",
    "fold_size = len(X) // 10\n",
    "for fold_id in range(fold_count):\n",
    "    fold_start = fold_size * fold_id\n",
    "    fold_end = fold_start + fold_size\n",
    "\n",
    "    if fold_id == 9:\n",
    "        fold_end = len(X)\n",
    "\n",
    "    X_valid = X[fold_start:fold_end]\n",
    "    Y_valid = Y[fold_start:fold_end]\n",
    "    X_train = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "    Y_train = np.concatenate([Y[:fold_start], Y[fold_end:]])\n",
    "\n",
    "    model = build_model(lr = 0.001)\n",
    "    file_path = \"CAPS4_%s_.hdf5\" %fold_id\n",
    "    es = EarlyStopping(monitor='val_loss',patience=5, mode='min')\n",
    "    rop = ReduceLROnPlateau(monitor='val_loss', patience=1, mode='min',epsilon=1e-6, factor=0.9)\n",
    "    ra_val = RocAucEvaluation(validation_data = (X_valid, Y_valid), interval = 1)\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "    history = model.fit(X_train, Y_train, batch_size = 256, epochs = 10, validation_data = (X_valid, Y_valid),\n",
    "                  verbose = 1, callbacks = [ra_val, check_point, es,rop])\n",
    "\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 46s 303us/step\n",
      "15957/15957 [==============================] - 5s 301us/step\n",
      "153164/153164 [==============================] - 47s 304us/step\n",
      "15957/15957 [==============================] - 5s 301us/step\n",
      "153164/153164 [==============================] - 47s 305us/step\n",
      "15957/15957 [==============================] - 5s 302us/step\n",
      "153164/153164 [==============================] - 47s 306us/step\n",
      "15957/15957 [==============================] - 5s 304us/step\n",
      "153164/153164 [==============================] - 47s 308us/step\n",
      "15957/15957 [==============================] - 5s 304us/step\n",
      "153164/153164 [==============================] - 47s 307us/step\n",
      "15957/15957 [==============================] - 5s 307us/step\n",
      "153164/153164 [==============================] - 47s 308us/step\n",
      "15957/15957 [==============================] - 5s 303us/step\n",
      "153164/153164 [==============================] - 47s 310us/step\n",
      "15957/15957 [==============================] - 5s 316us/step\n",
      "153164/153164 [==============================] - 48s 314us/step\n",
      "15957/15957 [==============================] - 5s 306us/step\n",
      "153164/153164 [==============================] - 47s 309us/step\n",
      "15958/15958 [==============================] - 5s 307us/step\n"
     ]
    }
   ],
   "source": [
    "list_of_preds = []\n",
    "list_of_vals = []\n",
    "list_of_y = []\n",
    "fold_count = 10\n",
    "fold_size = len(X) // 10\n",
    "for fold_id in range(0, fold_count):\n",
    "    fold_start = fold_size * fold_id\n",
    "    fold_end = fold_start + fold_size\n",
    "\n",
    "    if fold_id == 9:\n",
    "        fold_end = len(X)\n",
    "\n",
    "    X_valid = X[fold_start:fold_end]\n",
    "    Y_valid = Y[fold_start:fold_end]\n",
    "    X_train = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "    Y_train = np.concatenate([Y[:fold_start], Y[fold_end:]])\n",
    "\n",
    "    file_path = 'CAPS4_' + str(fold_id) + '_.hdf5'\n",
    "    model = build_model(lr = 0.001)\n",
    "    model.load_weights(file_path)\n",
    "    #model = load_model(file_path,custom_objects = {\"Capsule\": Capsule})\n",
    "    preds = model.predict(X_test, batch_size = 256, verbose = 1)\n",
    "    list_of_preds.append(preds)\n",
    "    vals = model.predict(X_valid, batch_size = 256, verbose = 1)\n",
    "    list_of_vals.append(vals)\n",
    "    list_of_y.append(Y_valid)\n",
    "test_predicts = np.zeros(list_of_preds[0].shape)\n",
    "for fold_predict in list_of_preds:\n",
    "    test_predicts += fold_predict\n",
    "\n",
    "test_predicts /= len(list_of_preds)\n",
    "submission = pd.read_csv('assets/raw_data/sample_submission.csv')\n",
    "submission[LIST_CLASSES] = test_predicts\n",
    "submission.to_csv('CAPS4_l2_test_data.csv', index=False)\n",
    "\n",
    "l2_data = pd.DataFrame(columns=['logits_' + c for c in LIST_CLASSES]+LIST_CLASSES)\n",
    "l2_data[['logits_' + c for c in LIST_CLASSES]] = pd.DataFrame(np.concatenate(list_of_vals,axis = 0))\n",
    "l2_data[LIST_CLASSES] = pd.DataFrame(np.concatenate(list_of_y,axis = 0))\n",
    "l2_data.to_csv('CAPS4_l2_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
